
# Домашнее задание к занятию "13.Системы мониторинга"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?
#
2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?
#
3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?
#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?
#
5. Опишите основные плюсы и минусы pull и push систем мониторинга.
#
6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus 
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios
#
7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        
    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.
#
9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.


### Ответы:    

1. 1.1 Производительность ЦПУ. Метрики загрузки ЦПУ, как средней загрузки, так и максимальной нагрузки. Это важно, так как вычисления загружают ЦПУ
   
   1.2 Метрика оперативной памяти, для мониторинга количества свободной памяти
   
   1.3 Пропускная способность. Показывает среднее время для обработки запроса
   
   1.4 Дисковое пространство
   
   1.5 Сетевая активность для определения объема входящего и исходящего трафика.
   
   1.6 Производительность HTTP. Метрики времени ответа сервера на HTTP-запросы, количество успешных и неуспешных запросов по кодам ответов (2xx, 4xx, 5xx).
   
   1.7 Нагрузка на сервер (load average) для оценки общей производительности сервера.    

2. Можно предложить следующие метрики:    
   2.1 Время отклика (Response Time): Эта метрика измеряет время, необходимое для обработки запросов вашей платформой. Оценивая это время в миллисекундах, вы можете определить, насколько быстро платформа реагирует на запросы клиентов, что в свою очередь позволяет оценить скорость и отзывчивость обслуживания.    

   2.2 Количество успешных запросов (Successful Requests): Эта метрика демонстрирует, сколько запросов успешно обработаны вашей платформой с ожидаемым результатом. Оценка надежности и стабильности работы основывается на этом показателе.    

   2.3 Уровень ошибок (Error Rate): Эта метрика показывает количество ошибок, возникающих в процессе обработки запросов. Это могут быть ошибки HTTP, проблемы в приложении или другие неполадки, влияющие на работу платформы. Низкий уровень ошибок свидетельствует о высоком качестве предоставляемых услуг.    

   2.4 Время выполнения задач (Task Execution Time): Если ваша платформа выполняет вычислительные задачи, измерение времени, потраченного на выполнение каждой задачи, может показать эффективность и скорость обработки. Это также помогает удостовериться, что задачи завершаются в разумные сроки.    

   2.5 Количество обращений клиентов (Customer Support Tickets): Эта метрика отражает количество обращений клиентов в службу поддержки. Она помогает оценить активность клиентов в поиске помощи и поддержки, что может свидетельствовать о возникновении проблем или потребности в более ясной документации.    

3. Можно предложить следующие решения:    
   3.1 Логирование на уровне приложения: Инструктировать разработчиков добавить логирование в свои приложения, чтобы записывать ошибки, исключения и другую важную информацию в лог-файлы.    
   
   3.2 Централизованное хранение: Использовать бесплатные и открытые решения, такие как ELK Stack (Elasticsearch, Logstash, Kibana) или Graylog, для централизованного сбора и анализа логов.    
   
   3.3 Настройка алертов: Создание автоматических алертов на основе определенных ключевых слов или шаблонов в лог-файлах для быстрого обнаружения и реагирования на ошибки.    

4. Ошибка в расчете SLA:
   Проблема заключается в том, что была использована неверная формула для расчета SLA. Эта формула (summ_2xx_requests / summ_all_requests) учитывает только успешные запросы (2xx коды), но должна учитывать как успешные, так и неуспешные запросы. Корректная формула для SLA должна выглядеть как: (summ_2xx_requests + summ_4xx_requests + summ_5xx_requests) / summ_all_requests.    
   
5. Push-модель плюсы:

   Мгновенность: Push-системы моментально отправляют данные мониторинга сразу после их сбора. Это особенно полезно для мониторинга в реальном времени или при работе с данными высокой частоты.
   
   Снижение нагрузки на клиентов: В push-системах клиентам или агентам не требуется самостоятельно запросить данные, так как они активно передаются в мониторинговую систему. Это может уменьшить нагрузку на      клиентскую инфраструктуру.

   Push-модель минусы:

   Сложная настройка: Настройка push-систем может быть более сложной, так как требуется правильно настроить механизмы передачи данных с клиентов или агентов в мониторинговую систему.
   
   Ограниченная гибкость: Push-системы могут ограничивать гибкость в выборе метрик и данных, которые отправляются. Это может зависеть от возможностей клиентской библиотеки или спецификаций передачи данных.

   Pull-модель плюсы:

   Простая настройка: В pull-системах агенты или клиенты сами запрашивают метрики у мониторинговой системы. Этот процесс обычно более понятен и легок в настройке.
   
   Гибкость: Агенты или клиенты могут выбирать, какие метрики им необходимы для сбора и отправки. Это обеспечивает гибкую настройку сбора данных в соответствии с потребностями.
   
   Масштабируемость: Pull-системы более просты в масштабировании для обработки большого объема данных, поскольку каждый клиент или агент может самостоятельно запросить данные.

   Pull-модель минусы:

   Задержка: В pull-системах возникает небольшая задержка между запросом данных и получением ответа. Это может быть недостаточно быстрым для реального времени или для сбора данных с высокой частотой.
   
   Дополнительная нагрузка на клиентов: В pull-системах клиентам или агентам приходится активно запрашивать данные у мониторинговой системы. Это может создать дополнительную нагрузку на клиентскую
   инфраструктуру.

6. Push: Prometheus, TICK
   Pull: Zabbix, Nagios
   Гибридные: VictoriaMetrics

7. ![alt text](https://github.com/bonanzza-web/monitoring-hw/blob/main/image/7.png)    

8. ![alt text](https://github.com/bonanzza-web/monitoring-hw/blob/main/image/8.png)

9. ![alt text](https://github.com/bonanzza-web/monitoring-hw/blob/main/image/9.png)


## Дополнительное задание (со звездочкой*) - необязательно к выполнению

1. Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.

2. В веб-интерфейсе откройте вкладку `Dashboards`. Попробуйте создать свой dashboard с отображением:

    - утилизации ЦПУ
    - количества использованного RAM
    - утилизации пространства на дисках
    - количество поднятых контейнеров
    - аптайм
    - ...
    - фантазируйте)
    
    ---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
